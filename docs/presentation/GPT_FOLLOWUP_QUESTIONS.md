# GPT 후속 질문 (작업 진행 중)

**작성일**: 2026-01-02 (Asia/Seoul)  
**상태**: 선택된 피처로 재학습 진행 중, RuntimeWarning 지속 발생

---

## 현재 상황

1. **선택된 19개 피처로 재학습 진행 중**
   - 피처 중요도 분석 완료 (누적 80%)
   - 하이퍼파라미터 튜닝 + 앙상블 포함
   - 예상 완료 시간: 10-15분

2. **RuntimeWarning 지속 발생**
   - `divide by zero`, `overflow`, `invalid value encountered in matmul`
   - LogisticRegression 학습 중 발생
   - 피처 클리핑 추가했지만 여전히 발생

3. **목표 지표 미달**
   - 현재: PR-AUC 0.0829, Precision@10 0.20, 경기당 알림 95개
   - 목표: PR-AUC ≥0.15, Precision@10 ≥0.40, 경기당 알림 10-20개

---

## 질문 1: RuntimeWarning 근본 해결 방법

**상황**: 
- 피처 클리핑 (`np.clip(-1e6, 1e6)`) 추가했지만 여전히 발생
- LogisticRegression의 `matmul` 연산 중 발생
- 표준화 후에도 클리핑 (`-10 ~ 10`) 적용했지만 지속

**질문**:
1. RuntimeWarning의 근본 원인은 무엇인가? (피처 분산, 상관관계, 스케일 문제?)
2. LogisticRegression 대신 다른 모델을 사용하는 것이 나을까? (예: HistGradientBoosting만 사용)
3. 피처 선택/전처리 단계에서 추가로 확인해야 할 사항은?
4. 이 경고를 무시하고 진행해도 모델 성능에 영향이 없는가?

---

## 질문 2: 선택된 피처 재학습 후 성능 개선 전략

**상황**:
- 53개 → 19개 피처로 축소 (누적 중요도 80%)
- 재학습 결과가 목표 지표에 미달할 가능성

**질문**:
1. 피처 수를 줄였는데 성능이 오히려 떨어질 수 있는가? (과적합 완화 vs 정보 손실)
2. 성능이 개선되지 않으면 다음 단계는? (피처 수 조정, 다른 선택 기준?)
3. 시퀀스 피처(최근 5초/10초 윈도우)를 더 강화하는 구체적 방법은?
4. GPT 리서치에서 언급한 "시퀀스 피처 다층화"의 구체적 구현 방법은?

---

## 질문 3: Precision@10 개선을 위한 랭킹 손실/후처리

**상황**:
- 현재 Precision@10 = 0.20 (목표: ≥0.40)
- GPT 리서치에서 "랭킹 목적함수/후처리"가 Precision@10 개선에 유리하다고 언급

**질문**:
1. "랭킹 손실"의 구체적 구현 방법은? (scikit-learn에서 가능한가?)
2. "후처리(게임 단위 top-k 안정화)"의 구체적 방법은?
3. Threshold 기반 vs Top-K 기반 알림 시스템의 trade-off는?
4. Precision@10을 0.20 → 0.40으로 올리기 위한 실전적인 방법은?

---

## 질문 4: 라벨 정의 재점검 (중복 양성 처리, Negative Sampling)

**상황**:
- 현재 라벨: `will_have_shot = any(type_name == "Shot" for future events in (t, t+10])`
- 같은 포제션 내 여러 이벤트가 전부 양성으로 라벨링될 수 있음

**질문**:
1. "중복 양성 처리"의 구체적 방법은? (첫 양성만 라벨링? 마지막 양성만?)
2. "Negative Sampling 완화"는 무엇을 의미하는가? (어떤 샘플을 제거/유지?)
3. 라벨 정의 변경이 모델 성능에 미치는 영향은?
4. 현재 라벨링 전략의 문제점과 개선 방안은?

---

## 질문 5: 모델 선택 및 앙상블 전략

**상황**:
- 현재: LogisticRegression + HistGradientBoostingClassifier + Voting + Stacking
- RuntimeWarning이 LogisticRegression에서 주로 발생

**질문**:
1. LogisticRegression을 제거하고 HistGradientBoosting만 사용하는 것이 나을까?
2. XGBoost/LightGBM 도입 시점과 방법은?
3. 앙상블 모델의 성능 개선 효과는 일반적으로 어느 정도인가?
4. 현재 데이터 규모(양성 비율 4.61%)에서 가장 적합한 모델은?

---

## 질문 6: 경기당 알림 수 조정 전략

**상황**:
- 현재: 95.42개/경기 (목표: 10-20개)
- Threshold 조정 vs Top-K 기반 시스템

**질문**:
1. Threshold를 높여서 알림 수를 줄이는 것의 trade-off는?
2. Top-K 기반 시스템의 구체적 구현 방법은? (게임 단위? 세션 단위?)
3. Precision@10=0.20을 유지하면서 알림 수를 줄이는 방법은?
4. 운영 관점에서 가장 실용적인 알림 정책은?

---

## 우선순위

1. **즉시 필요**: 질문 1 (RuntimeWarning 해결)
2. **학습 완료 후**: 질문 2, 3 (성능 개선 전략)
3. **다음 단계**: 질문 4, 5, 6 (장기 개선 전략)

---

## 참고

- 현재 학습 진행 중: 선택된 19개 피처로 재학습
- 학습 완료 후 성능 비교 결과를 바탕으로 추가 질문 예정

