# GPT 답변 정리 (피처 축소 성능 하락 분석)

**작성일**: 2026-01-02 (Asia/Seoul)  
**질문**: 피처 53→19로 축소 후 성능 하락 원인 및 개선 방안

---

## 핵심 요약

**문제**: 피처 축소(53→19)로 PR-AUC 하락(-14%), 경기당 알림 2배 증가

**근본 원인**: 
- 단순 중요도 누적은 **상호작용 피처를 고려하지 않음**
- 모델의 비선형 관계 학습 손실
- 정보 손실로 인한 성능 저하

**해결 방향**:
1. 원래 53개 피처로 복원 또는 다른 선택 기준 적용
2. 상호작용 피처 생성
3. 시퀀스 피처 다층화 (1초/5초/10초/20초)
4. Wrapper 방법 또는 SHAP 기반 재선정

---

## 1. 피처 수를 줄였는데 성능이 오히려 떨어진 이유

### 핵심 포인트

- **피처 선택은 단순히 중요도 누적 80%를 채웠다고 해서 성능 유지가 보장되지 않습니다.**
- 모델이 **학습 과정에서 상호작용/비선형 관계를 학습**하는 경우, 단일 중요도 기준으로 제거하면 그 상호작용 부분 정보가 사라질 수 있습니다.
- 53개 모두 합쳐서 모델이 대응했던 복잡한 패턴/조건이 19개로 줄어들면서 **정보 손실이 발생**했고, 이로 인해 PR-AUC가 떨어진 것으로 보입니다.
- 특히 GradientBoosting/Tree 계열은 여러 피처 조합/상호작용에 기반해 예측하기 때문에, **단순한 중요도 누적으로 선택하면 성능이 깨지기도 합니다**.

**출처**: [arXiv - The impact of feature importance methods](https://arxiv.org/pdf/2202.02389)

---

## 2. 누적 중요도 80% 기준 선택에도 성능이 하락하는 이유

### 이유 정리

1. **상호작용 피처가 빠졌을 가능성**
   - 중요도 기반 선택은 **각 피처의 개별적 중요도만 평가**합니다.
   - 두 피처가 개별적으로 낮게 평가돼도 **함께 있을 때 의미가 있는 조합**이 있을 수 있습니다. 이런 상호작용 정보가 빠지면 모델 성능이 떨어집니다.

2. **모델/데이터 특성 반영 부족**
   - 피처 중요도는 모델/데이터에 따라 달라지며 단순히 숫자 누적만으로 결정하면 안 됩니다.

3. **모델의 internal representation 손실**
   - GradientBoosting 같은 모델은 여러 피처를 쪼개서 학습하는데 피처가 줄어들면 **구분 가능한 분할/의사결정 경계**가 약해질 수 있습니다.

**출처**: [Built In - Understanding Feature Importance](https://builtin.com/data-science/feature-importance)

---

## 3. 경기당 알림 수가 2배 이상 증가한 이유

### 원인 분석

- **Threshold가 자동으로 낮아졌기 때문**입니다.
  - 피처 수가 줄어들면서 전체 예측확률 분포가 바뀌었고, 같은 threshold(예: 0.5)에서 양성 판정이 더 많이 나옵니다.
- HistGradientBoostingClassifier는 확률 분포가 상대적으로 **덜 조정되거나 편향될 수 있는 성향**이 있어, 피처 축소 후 decision boundary가 유연성을 잃고 양성 판정 쪽으로 치우쳤을 수 있습니다.

**시사점**:
- threshold calibration 또는 후처리 없이 단순 예측확률 기반 판정을 유지하면 **알림 과다 발생**이 흔히 나타납니다.

---

## 4. 성능이 개선되지 않는 경우 다음 단계

### 권장 접근

1. **피처 수 조정/선택 기준 변경**
   - 단순 누적 중요도 기준 외에도 **Wrapper/Sequential 방법** 또는 **상호작용을 반영한 방법**을 고려해야 합니다.

2. **상호작용 피처 생성**
   - 원본 feature 쌍의 곱/비율/차이처럼 상호작용 피처를 생성하여 추가합니다.

3. **Permutation importance나 SHAP 기반 재선정**
   - 개별 중요도뿐 아니라 **interactions를 고려한 중요도 측정** 방법으로 재선정합니다.

**출처**: [PIPI - 특성 선택(Feature Selection)](https://pipiiiiii.tistory.com/270)

---

## 5. 53개 피처로 돌아가야 하나?

### 판단 가이드라인

- 지금처럼 단순 중요도 누적만으로 줄이는 경우,
  -> 성능 저하가 지속되므로
  -> **원래의 53개 피처로 돌아가거나, 다른 선택 기준을 적용하는 것이 합리적**입니다.

**대안**:
- **단일 중요도 기준이 아닌**,
  - 모델별 상호작용/연관성을 고려한 피처 조합 선택
  - Wrapper 방법으로 실험적 제거/추가
    -> 이런 방법이 좀 더 성능 보존에 유리합니다.

---

## 6. 시퀀스 피처 강화의 구체적 방법

### 구조화된 접근

1. **윈도우 기반 집계 생성**
   - 최근 5초/10초 내의 패스 횟수, 드리블/턴오버 횟수, 변화량 등
   - 이동 평균/분산/최대/최소 등을 계산하여 추가

2. **시간 차 특성**
   - 이벤트 간의 시간 간격, 누적 거리 같은 동적 특성

3. **상태 전이 피처**
   - 예: "공 소유 + 공격 진입" → "슈팅 위치 근접"으로 넘어가는 빈도

이런 시퀀스/시간 윈도우 피처는 **일반 피처보다 정보량이 풍부**하고 모델의 예측력을 높이는 데 도움이 됩니다.

---

## 7. "시퀀스 피처 다층화"의 구체적 의미

### 실용적인 구현 설명

**다층화란?**
- 여러 시간 범위(예: 1초/5초/10초/20초)를 동시에 반영하여 특성을 구성하는 것
- 이는 단일 윈도우 특성보다 **다양한 순간/추세를 동시에 포착**합니다.

**구체 구현 사례**:
```python
# 최근 N초 window에서의 누적 횟수
df['past5s_pass_count'] = df[df.time_diff <= 5].groupby('game_id')['pass_event'].transform('sum')
df['past10s_shot_count'] = df[df.time_diff <= 10].groupby('game_id')['shot_event'].transform('sum')

# 이동 평균/벡터 길이
df['velocity_mean5s'] = df[df.time_diff <= 5].groupby('player_id')['velocity'].transform('mean')
...
```

- 이렇게 생성된 다층 특성은 모델이 **짧은 순간의 패턴 + 긴 관점의 흐름**을 동시에 학습하게 합니다.

---

## 정리: 지금 상황 교정

### 현재 피처 축소 방식의 문제

- 단순 feature importance 누적은 *상호작용을 고려하지 않음* → 정보 손실 → 성능 하락

### 개선 방향

1. **원래 53개 피처로 부분 복원 + 상호작용 피처 생성**
2. **시퀀스 특성 강화** (5~20초 여러 계층)
3. **재선정 기준 강화** (Wrapper/교차 검증 기반 선택)
4. **Threshold/랭킹 후처리**로 경기당 알림 수 조절

---

## 참고 링크

- [PIPI - 특성 선택(Feature Selection)](https://pipiiiiii.tistory.com/270)
- [arXiv - The impact of feature importance methods](https://arxiv.org/pdf/2202.02389)
- [Built In - Understanding Feature Importance](https://builtin.com/data-science/feature-importance)

